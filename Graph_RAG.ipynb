{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twIRf5ZkzPZP"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This project implements an intelligent Q&A system for exploring a database schema stored in Neo4j.\n",
        "It works as follows:\n",
        "1. Load a JSON schema file describing tables, columns, and relationships.\n",
        "2. Store this schema in Neo4j as nodes (:Table) and relationships (:FK for foreign keys).\n",
        "3. Build a FAISS vector index from table and column descriptions for semantic search.\n",
        "4. Use Groq LLM (via API) to:\n",
        "   - Understand the user's natural language question.\n",
        "   - Generate a safe Cypher query targeting only the schema graph (no row-level data).\n",
        "5. Execute the generated Cypher query on Neo4j and retrieve results.\n",
        "6. Analyze results and return a clear Arabic summary + preview (relationships, table names, columns, etc.).\n",
        "7. The workflow is managed with LangGraph, ensuring a step-by-step process:\n",
        "   reasoning → Cypher generation → execution → analysis → output.\n",
        "\"\"\"\n",
        "!pip install -q langgraph groq neo4j sentence-transformers faiss-cpu tqdm requests python-dotenv pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EL8K3eN3F8yE"
      },
      "outputs": [],
      "source": [
        "import os, json, re, pickle, traceback\n",
        "from getpass import getpass\n",
        "from neo4j import GraphDatabase\n",
        "import requests\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "from tqdm import tqdm\n",
        "from typing import List, Dict, Any, Tuple\n",
        "\n",
        "# LangGraph\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "n43GiMdjzrp-",
        "outputId": "23a70408-c4eb-497b-f282-f1244c0cf697"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab detected: use file upload UI…\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e45fe449-cf4c-4453-b2f6-0fd486121c8b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e45fe449-cf4c-4453-b2f6-0fd486121c8b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving mock_db_schema (1).json to mock_db_schema (1) (10).json\n",
            "Loaded schema keys: ['tables']\n",
            "Tables found: ['users', 'addresses', 'categories', 'suppliers', 'products', 'orders', 'order_items', 'shipments', 'payments', 'reviews']\n"
          ]
        }
      ],
      "source": [
        "# ----------------------------------------------------\n",
        "# Step 1: Detect if running inside Google Colab\n",
        "# ----------------------------------------------------\n",
        "# - Try to import the Colab \"files\" module.\n",
        "# - If successful → open a file picker UI to upload the schema JSON file.\n",
        "# - Get the uploaded file name and set it as schema_path.\n",
        "# - If running locally (import fails) → ask the user to manually type the path.\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(\"Colab detected: use file upload UI…\")\n",
        "    uploaded = files.upload()\n",
        "    schema_path = list(uploaded.keys())[0]\n",
        "except Exception:\n",
        "    print(\"Colab not detected. Set local path to your schema JSON file:\")\n",
        "    schema_path = input(\"Path to schema.json: \").strip()\n",
        "\n",
        "with open(schema_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    schema = json.load(f)\n",
        "\n",
        "print(\"Loaded schema keys:\", list(schema.keys()))\n",
        "if \"tables\" in schema:\n",
        "    print(\"Tables found:\", list(schema[\"tables\"].keys()))\n",
        "else:\n",
        "    print(\"Warning: 'tables' key not found in schema; check file.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcXzBSujzrr5",
        "outputId": "6e613df5-aa77-4d74-fd5b-9c71ddc761a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to Neo4j!\n"
          ]
        }
      ],
      "source": [
        "# This block checks if Neo4j and Groq API credentials are already set as environment variables.\n",
        "# If not, it prompts the user to input them (securely for passwords and API keys)\n",
        "# and stores them temporarily for the current session.\n",
        "# After that, it tries to connect to the Neo4j database and prints a confirmation message if successful,\n",
        "# or an error message if the connection fails\n",
        "if not  os.getenv(\"NEO4J_URI\"):\n",
        "    print(\"Enter Neo4j credentials (or leave blank to skip Neo4j steps)\")\n",
        "    neo_uri = input(\"Neo4j URI (bolt://localhost:7687 or neo4j+s://...): \").strip()\n",
        "    if neo_uri:\n",
        "        neo_user = input(\"Neo4j user (e.g. neo4j): \").strip()\n",
        "        neo_pwd = getpass(\"Neo4j password (hidden): \")\n",
        "        os.environ[\"NEO4J_URI\"] = neo_uri\n",
        "        os.environ[\"NEO4J_USER\"] = neo_user\n",
        "        os.environ[\"NEO4J_PASSWORD\"] = neo_pwd\n",
        "\n",
        "if not os.getenv(\"GROQ_API_KEY\"):\n",
        "    k = getpass(\"Enter GROQ_API_KEY (hidden) — leave blank to skip LLM calls: \")\n",
        "    if k:\n",
        "        os.environ[\"GROQ_API_KEY\"] = k\n",
        "\n",
        "try:\n",
        "    driver = GraphDatabase.driver(\n",
        "        os.getenv(\"NEO4J_URI\"),\n",
        "        auth=(os.getenv(\"NEO4J_USER\"), os.getenv(\"NEO4J_PASSWORD\"))\n",
        "    )\n",
        "    with driver.session() as sess:\n",
        "        res = sess.run(\"RETURN 'Connected to Neo4j!' AS msg\")\n",
        "        print(res.single()[\"msg\"])\n",
        "except Exception as e:\n",
        "    print(\"Failed to connect to Neo4j:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjdbJoopzruP"
      },
      "outputs": [],
      "source": [
        "# This section defines file paths used to store and retrieve the FAISS index, metadata,\n",
        "# and records for schema search functionality. All files are saved in the current directory.\n",
        "DATA_PATH = \"./\"ن\n",
        "FAISS_INDEX_PATH = os.path.join(DATA_PATH, \"faiss_index.faiss\")\n",
        "META_PATH = os.path.join(DATA_PATH, \"faiss_meta.pkl\")\n",
        "RECORDS_PATH = os.path.join(DATA_PATH, \"records.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHy-X7TFzrzU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "012e58d5-43e1-4d31-f2fa-79c4926a60bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingesting schema to Neo4j: tables count = 10\n",
            "Schema ingest completed.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "# This function ingests a JSON database schema into Neo4j.\n",
        "# It creates a (Table) node for each table with a 'columns' property storing column metadata as JSON,\n",
        "# and creates :FK relationships between tables based on foreign key-like column names (ending with '_id').\n",
        "# Primary keys and self-references are excluded to avoid redundant or invalid relationships.\n",
        "import json\n",
        "\n",
        "def ingest_schema_to_neo4j_compact(schema, driver):\n",
        "    if not driver:\n",
        "        print(\"No Neo4j driver; skipping schema ingest.\")\n",
        "        return\n",
        "\n",
        "\n",
        "    tables = schema.get(\"tables\", schema)\n",
        "    table_names_lower = {name.lower(): name for name in tables}\n",
        "    print(\"Ingesting schema to Neo4j: tables count =\", len(tables))\n",
        "\n",
        "    with driver.session() as sess:\n",
        "\n",
        "        sess.run(\"MATCH (n) DETACH DELETE n\")\n",
        "\n",
        "\n",
        "        sess.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (t:Table) REQUIRE t.name IS UNIQUE\")\n",
        "\n",
        "\n",
        "        for tname, tinfo in tables.items():\n",
        "            cols_data = [\n",
        "                {\n",
        "                    \"name\": col.get(\"name\"),\n",
        "                    \"data_type\": col.get(\"data_type\"),\n",
        "                    \"description\": col.get(\"description\")\n",
        "                }\n",
        "                for col in tinfo.get(\"columns\", [])\n",
        "            ]\n",
        "            sess.run(\"\"\"\n",
        "                MERGE (t:Table {name:$tname})\n",
        "                SET t.columns = $columns_json\n",
        "            \"\"\", tname=tname, columns_json=json.dumps(cols_data, ensure_ascii=False))\n",
        "\n",
        "\n",
        "        seen_links = set()\n",
        "        for tname, tinfo in tables.items():\n",
        "            for col in tinfo.get(\"columns\", []):\n",
        "                cname = (col.get(\"name\") or \"\").lower()\n",
        "                desc = (col.get(\"description\") or \"\").lower()\n",
        "\n",
        "                target_table = None\n",
        "\n",
        "\n",
        "                if \"foreign key\" in desc:\n",
        "                    for cand in table_names_lower:\n",
        "                        if cand in desc:\n",
        "                            target_table = table_names_lower[cand]\n",
        "                            break\n",
        "\n",
        "\n",
        "                if not target_table and cname.endswith(\"_id\") and \"primary key\" not in desc:\n",
        "                    target_guess = cname[:-3]\n",
        "                    candidates = {target_guess, target_guess + \"s\", target_guess.rstrip(\"s\")}\n",
        "\n",
        "                    for cand in candidates:\n",
        "                        if cand in table_names_lower:\n",
        "                            target_table = table_names_lower[cand]\n",
        "                            break\n",
        "\n",
        "\n",
        "                    if not target_table and target_guess == tname.lower():\n",
        "                        target_table = tname\n",
        "\n",
        "                if not target_table:\n",
        "                    continue\n",
        "\n",
        "\n",
        "                key = (tname, target_table, cname)\n",
        "                if key in seen_links:\n",
        "                    continue\n",
        "                seen_links.add(key)\n",
        "\n",
        "\n",
        "                sess.run(\"\"\"\n",
        "                    MATCH (src:Table {name:$src}), (dst:Table {name:$dst})\n",
        "                    MERGE (src)-[:FK {column:$col}]->(dst)\n",
        "                \"\"\", src=tname, dst=target_table, col=cname)\n",
        "\n",
        "    print(\"Schema ingest completed.\")\n",
        "\n",
        "\n",
        "\n",
        "ingest_schema_to_neo4j_compact(schema, driver)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_Qc_-Hhzr19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f00d3d63-2f1f-433a-8d05-e27a96a747a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📋 Tables in schema:\n",
            " - addresses\n",
            " - categories\n",
            " - order_items\n",
            " - orders\n",
            " - payments\n",
            " - products\n",
            " - reviews\n",
            " - shipments\n",
            " - suppliers\n",
            " - users\n",
            "\n",
            "🔗 Foreign Key Relationships:\n",
            "  addresses --[user_id]-> users\n",
            "  order_items --[order_id]-> orders\n",
            "  order_items --[product_id]-> products\n",
            "  orders --[payment_id]-> payments\n",
            "  orders --[shipment_id]-> shipments\n",
            "  orders --[user_id]-> users\n",
            "  payments --[order_id]-> orders\n",
            "  products --[category_id]-> categories\n",
            "  products --[supplier_id]-> suppliers\n",
            "  reviews --[product_id]-> products\n",
            "  reviews --[user_id]-> users\n",
            "  shipments --[address_id]-> addresses\n",
            "  shipments --[order_id]-> orders\n",
            "  users --[address_id]-> addresses\n"
          ]
        }
      ],
      "source": [
        "# This function prints a quick overview of the database schema from Neo4j.\n",
        "# It lists all tables (Table nodes) in alphabetical order, then shows all foreign key (:FK) relationships\n",
        "# between tables in the format \"TableA --[column_name]-> TableB\". If no relationships are found, it states that explicitly.\n",
        "def show_schema_in_console(driver):\n",
        "    with driver.session() as sess:\n",
        "\n",
        "        print(\" Tables in schema:\")\n",
        "        results = sess.run(\"MATCH (t:Table) RETURN t.name AS name ORDER BY name\")\n",
        "        tables = [record[\"name\"] for record in results]\n",
        "        for t in tables:\n",
        "            print(\" -\", t)\n",
        "\n",
        "        print(\"\\n Foreign Key Relationships:\")\n",
        "        results = sess.run(\"\"\"\n",
        "            MATCH (a:Table)-[r:FK]->(b:Table)\n",
        "            RETURN a.name AS src, r.column AS col, b.name AS dst\n",
        "            ORDER BY src, dst, col\n",
        "        \"\"\")\n",
        "\n",
        "        if results.peek():\n",
        "            for record in results:\n",
        "                src, col, dst = record[\"src\"], record[\"col\"], record[\"dst\"]\n",
        "                if src == dst:\n",
        "\n",
        "                    print(f\"  {src} --[{col}]-> {dst} (self-reference)\")\n",
        "                else:\n",
        "                    print(f\"  {src} --[{col}]-> {dst}\")\n",
        "        else:\n",
        "            print(\" (No FK relationships found)\")\n",
        "\n",
        "\n",
        "show_schema_in_console(driver)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huWW1amBzr4h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "e40fb782ff5e4effae68cdd53faa9aeb",
            "25730ebb23cb4cbdadba8af6f9b510bb",
            "c9f9d712bca641f99ea55fcabcf207ac",
            "eb64911f78f84cd39d3071d35196d2cd",
            "4b3aec6e05534e998c30271684e9c684",
            "fedcddb9543643f786a39cbbe25cd500",
            "14ffb06c91e5435386f30e59ce177930",
            "0fcddb30eb034e269eea18855dd4401c",
            "a6859b8823dc49fb9b0da8baf222c40c",
            "84bab26ac0784bf59a49c8721914ace0",
            "474b4c6bdf5b4502acb505ba1e18e5f3"
          ]
        },
        "outputId": "f58c4ba3-6ea9-4651-a95e-4e72cb36ac4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 111 schema entries for embeddings.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e40fb782ff5e4effae68cdd53faa9aeb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built FAISS index. n_items: 111\n",
            "Saved FAISS index & metadata.\n"
          ]
        }
      ],
      "source": [
        "# This section processes the JSON schema to prepare it for semantic search.\n",
        "# 1. Extracts all table names and their column details into a text list (`texts`) and a metadata list (`meta`).\n",
        "# 2. Generates embeddings for each text entry using the 'all-MiniLM-L6-v2' SentenceTransformer model.\n",
        "# 3. Builds a FAISS L2 index for efficient similarity search across schema elements.\n",
        "# 4. Saves both the FAISS index and the associated metadata to disk for later retrieval.\n",
        "\n",
        "DATA_PATH = \"./\"\n",
        "FAISS_INDEX_PATH = os.path.join(DATA_PATH, \"schema_faiss_index.faiss\")\n",
        "META_PATH = os.path.join(DATA_PATH, \"schema_meta.pkl\")\n",
        "\n",
        "texts, meta = [], []\n",
        "for table_name, table_info in schema.get(\"tables\", {}).items():\n",
        "    texts.append(f\"Table: {table_name}\")\n",
        "    meta.append({\"type\": \"table\", \"name\": table_name})\n",
        "\n",
        "    for col in table_info.get(\"columns\", []):\n",
        "        col_name = col.get(\"name\", \"\")\n",
        "        col_desc = col.get(\"description\", \"\")\n",
        "        full_text = f\"Column: {col_name} - {col_desc} (Table: {table_name})\"\n",
        "        texts.append(full_text)\n",
        "        meta.append({\n",
        "            \"type\": \"column\",\n",
        "            \"table\": table_name,\n",
        "            \"name\": col_name,\n",
        "            \"description\": col_desc\n",
        "        })\n",
        "\n",
        "print(f\"Extracted {len(texts)} schema entries for embeddings.\")\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "embeddings = model.encode(texts, convert_to_numpy=True, show_progress_bar=True)\n",
        "d = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(d)\n",
        "index.add(embeddings)\n",
        "print(\"Built FAISS index. n_items:\", index.ntotal)\n",
        "\n",
        "faiss.write_index(index, FAISS_INDEX_PATH)\n",
        "with open(META_PATH, \"wb\") as f:\n",
        "    pickle.dump({\"meta\": meta, \"texts\": texts}, f)\n",
        "print(\"Saved FAISS index & metadata.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1baR-v8zr6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "151ae85f-ba71-47bc-e169-5a2531659116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loaded Schema FAISS index\n",
            " Loaded schema metadata length: 111\n"
          ]
        }
      ],
      "source": [
        "# This section handles loading and searching the schema's FAISS index.\n",
        "# 1. `load_schema_faiss()` loads the FAISS index and metadata (`meta` and `texts`) from disk if available.\n",
        "# 2. After loading, it confirms availability of the index and metadata.\n",
        "# 3. `search_schema(query, top_k)` encodes the query into embeddings, searches the FAISS index for the top-k most similar schema entries,\n",
        "#    and returns results containing the similarity score, matched text, and metadata.\n",
        "\n",
        "def load_schema_faiss():\n",
        "    idx = faiss.read_index(FAISS_INDEX_PATH) if os.path.exists(FAISS_INDEX_PATH) else None\n",
        "    mt = None; tx = None\n",
        "    if os.path.exists(META_PATH):\n",
        "        with open(META_PATH, \"rb\") as f:\n",
        "            cont = pickle.load(f)\n",
        "            if isinstance(cont, dict) and \"meta\" in cont and \"texts\" in cont:\n",
        "                mt, tx = cont[\"meta\"], cont[\"texts\"]\n",
        "    return idx, mt, tx\n",
        "\n",
        "index, meta, texts = load_schema_faiss()\n",
        "if index is not None: print(\"  Loaded Schema FAISS index\")\n",
        "if meta is not None: print(\" Loaded schema metadata length:\", len(meta))\n",
        "\n",
        "def search_schema(query, top_k=5):\n",
        "    if index is None or meta is None or texts is None:\n",
        "        print(\" Schema index or metadata not loaded.\")\n",
        "        return []\n",
        "    q_emb = model.encode([query], convert_to_numpy=True)\n",
        "    D, I = index.search(q_emb, top_k)\n",
        "    results = []\n",
        "    for dist, idx in zip(D[0], I[0]):\n",
        "        if idx < 0: continue\n",
        "        results.append({\"score\": float(dist), \"text\": texts[idx], \"meta\": meta[idx], \"meta_idx\": int(idx)})\n",
        "    return results\n",
        "\n",
        "\n",
        "# This function assembles a textual summary of retrieved schema data.\n",
        "# It takes:\n",
        "#   - faiss_results: list of FAISS search matches (score + text + metadata)\n",
        "#   - neo4j_nodes: optional list of Neo4j graph node dictionaries\n",
        "#   - max_chunks: limit for number of FAISS results to include\n",
        "# Output:\n",
        "#   - Returns a combined string with:\n",
        "#       1) Top FAISS matches (score + description)\n",
        "#       2) Optional JSON previews of Neo4j nodes (truncated to 400 chars each)\n",
        "\n",
        "\n",
        "def assemble_schema_context(faiss_results, neo4j_nodes=None, max_chunks=5):\n",
        "    parts = []\n",
        "    parts.append(\"=== Retrieved schema entries ===\")\n",
        "    for i, r in enumerate(faiss_results[:max_chunks]):\n",
        "        parts.append(f\"[Result {i+1}] score={r['score']:.4f} → {r['text']}\")\n",
        "    parts.append(\"\\n=== Graph nodes summary ===\")\n",
        "    if neo4j_nodes:\n",
        "        for n in neo4j_nodes:\n",
        "            parts.append(json.dumps(n, ensure_ascii=False)[:400])\n",
        "    return \"\\n\".join(parts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fu5UzTzBx2s"
      },
      "outputs": [],
      "source": [
        "# This function creates a complete snapshot of the database schema from Neo4j.\n",
        "# It retrieves:\n",
        "#   1) All table names (:Table nodes) and their columns (parsed from JSON string)\n",
        "#   2) All foreign key relationships (:FK edges) between tables\n",
        "# Output:\n",
        "#   - A dictionary with:\n",
        "#       \"tables\": list of table names\n",
        "#       \"table_columns\": mapping table_name -> list of column names\n",
        "#       \"fks\": list of FK relationships (start_table, fk_column, end_table)\n",
        "\n",
        "def get_schema_snapshot(driver) -> Dict[str, Any]:\n",
        "    snap = {\"tables\": [], \"fks\": [], \"table_columns\": {}}\n",
        "    with driver.session() as sess:\n",
        "        res = sess.run(\"MATCH (t:Table) RETURN t.name AS name, t.columns AS columns ORDER BY name\")\n",
        "        for r in res:\n",
        "            tname = r[\"name\"]\n",
        "            snap[\"tables\"].append(tname)\n",
        "            cols_list = []\n",
        "            cols_str = r.get(\"columns\")\n",
        "            if isinstance(cols_str, str) and cols_str.strip():\n",
        "                try:\n",
        "                    cols = json.loads(cols_str)\n",
        "                    cols_list = [c.get(\"name\") for c in cols if isinstance(c, dict)]\n",
        "                except:\n",
        "                    pass\n",
        "            snap[\"table_columns\"][tname] = cols_list\n",
        "\n",
        "        res_fk = sess.run(\"\"\"\n",
        "            MATCH (t1:Table)-[r:FK]->(t2:Table)\n",
        "            RETURN t1.name AS start_table, r.column AS fk_column, t2.name AS end_table\n",
        "            ORDER BY start_table, end_table, fk_column\n",
        "        \"\"\")\n",
        "        snap[\"fks\"] = res_fk.data()\n",
        "    return snap\n",
        "\n",
        "# This function converts a schema snapshot (from get_schema_snapshot)\n",
        "# into a readable text format showing:\n",
        "#   1) All tables with up to 12 of their columns (and count of extra columns if any)\n",
        "#   2) All foreign key relationships in the format: table --[column]-> table\n",
        "# Returns a multi-line string ready for display or inclusion in prompts.\n",
        "\n",
        "def render_schema_text(snapshot: Dict[str, Any]) -> str:\n",
        "    lines = [\"TABLES:\"]\n",
        "    for t in snapshot[\"tables\"]:\n",
        "        cols = snapshot[\"table_columns\"].get(t) or []\n",
        "        prev = \", \".join(cols[:12])\n",
        "        extra = \"\" if len(cols) <= 12 else f\" (+{len(cols)-12} more)\"\n",
        "        lines.append(f\" - {t}: {prev}{extra}\")\n",
        "    lines.append(\"\\nFOREIGN KEYS (Table --[column]-> Table):\")\n",
        "    for fk in snapshot[\"fks\"]:\n",
        "        lines.append(f\" - {fk['start_table']} --[{fk.get('fk_column','?')}]-> {fk['end_table']}\")\n",
        "    return \"\\n\".join(lines)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LH8Lf5XBx4a"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "FORBIDDEN = re.compile(\n",
        "    r\"\\b(CREATE|MERGE|DELETE|SET|DROP|CALL\\s+dbms|CALL\\s+db\\.|apoc\\.[\\w.]*write|LOAD\\s+CSV)\\b\",\n",
        "    re.I\n",
        ")\n",
        "\n",
        "def extract_cypher(text: str) -> str:\n",
        "\n",
        "\n",
        "\n",
        "    text = re.sub(r\"(?i)^here is the cypher query[^\\n]*:\\n*\", \"\", text.strip())\n",
        "\n",
        "\n",
        "    m = re.search(r\"```(?:cypher)?\\s*([\\s\\S]+?)```\", text, flags=re.I)\n",
        "    if m:\n",
        "        text = m.group(1).strip()\n",
        "\n",
        "\n",
        "    text = re.sub(r\"(?i)^i apologize[^\\n]*\\n*\", \"\", text)\n",
        "\n",
        "\n",
        "    if not re.match(r\"^(MATCH|RETURN|WITH|CALL)\", text.strip(), re.I):\n",
        "        raise ValueError(f\"Invalid Cypher start: {text[:50]}\")\n",
        "\n",
        "\n",
        "    if FORBIDDEN.search(text):\n",
        "        raise ValueError(f\"Forbidden Cypher command detected: {text}\")\n",
        "\n",
        "    return text.strip()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ropNWaX54lDy"
      },
      "outputs": [],
      "source": [
        "def generate_cypher_from_groq(question: str, schema_text: str, memory_text: str, model: str = \"llama3-8b-8192\") -> str:\n",
        "    import os\n",
        "    import requests\n",
        "\n",
        "    api_key = os.getenv(\"GROQ_API_KEY\")\n",
        "    if not api_key:\n",
        "        raise RuntimeError(\"GROQ_API_KEY not set in environment\")\n",
        "\n",
        "    url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {api_key}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "\n",
        "    system_prompt = f\"\"\"\n",
        "You are an AI assistant generating valid Cypher queries for Neo4j.\n",
        "The database stores the schema as a graph:\n",
        "- Each table is a node with label :Table and property \"name\".\n",
        "- Each table node also has a property \"columns\" (JSON list of columns with descriptions).\n",
        "- Relationships between tables are stored as :FK edges with property \"column\".\n",
        "\n",
        "STRICT RULES:\n",
        "- You MUST NOT put {{}} property filters inside a MATCH relationship pattern. This is FORBIDDEN.\n",
        "- If you need to filter by relationship property, you MUST use a WHERE clause AFTER the MATCH.\n",
        "- You MUST always use the label :Table for all nodes.\n",
        "- You MUST filter specific table names using WHERE t.name = \"<table_name>\".\n",
        "- Never use labels like :users, :orders, :products. They do not exist.\n",
        "- Always access properties as t.name or t.columns (never bare `name`).\n",
        "- Output must start with MATCH, RETURN, WITH, or CALL.\n",
        "- Return ONLY the Cypher query. Do not include explanations or comments.\n",
        "- When matching two :Table nodes (even if they are the same table),\n",
        "  you MUST use different variables (t1, t2).\n",
        "  Example of self-join:\n",
        "  MATCH (t1:Table)-[r:FK]->(t2:Table)\n",
        "  WHERE t1.name = \"categories\" AND t2.name = \"categories\" AND r.column = \"parent_category_id\"\n",
        "  RETURN t1.name, r.column, t2.name\n",
        "\n",
        "IMPORTANT:\n",
        "- Your ENTIRE output MUST be ONLY one valid Cypher query.\n",
        "- Do NOT include apologies, explanations, markdown, or text outside the Cypher.\n",
        "- If unsure, still output a best-effort Cypher query (never natural language).\n",
        "INTENTS:\n",
        "\n",
        "1. **Relations (foreign key relationships)**\n",
        "   Pattern:\n",
        "   MATCH (t1:Table)-[r:FK]->(t2:Table)\n",
        "   [Optional WHERE r.column = \"<column>\"]\n",
        "   RETURN\n",
        "     t1.name AS `Table 1`,\n",
        "     r.column AS `FK Name`,\n",
        "     t2.name AS `Table 2`\n",
        "\n",
        "2. **Columns of a table**\n",
        "   Pattern:\n",
        "   MATCH (t:Table)\n",
        "   WHERE t.name = \"<table_name>\"\n",
        "   RETURN t.columns AS Columns\n",
        "\n",
        "3. **Primary key of a table**\n",
        "   Same query as columns:\n",
        "   MATCH (t:Table)\n",
        "   WHERE t.name = \"<table_name>\"\n",
        "   RETURN t.columns AS Columns\n",
        "   (the analysis step will extract the column whose description contains \"Primary Key\")\n",
        "\n",
        "4. **Foreign key columns of a table**\n",
        "   Same query as columns:\n",
        "   MATCH (t:Table)\n",
        "   WHERE t.name = \"<table_name>\"\n",
        "   RETURN t.columns AS Columns\n",
        "   (the analysis step will extract the columns whose description contains \"Foreign Key\")\n",
        "\n",
        "5. **List all tables**\n",
        "   MATCH (t:Table)\n",
        "   RETURN t.name AS Table\n",
        "\n",
        "6. **Find tables with a specific column name**\n",
        "   MATCH (t:Table)\n",
        "   WHERE any(col IN apoc.convert.fromJsonList(t.columns) WHERE col.name = \"<column_name>\")\n",
        "   RETURN t.name AS Table\n",
        "\n",
        "Few-shot examples:\n",
        "\n",
        "Example 1:\n",
        "Question: \"Show all foreign key relationships.\"\n",
        "Cypher:\n",
        "MATCH (t1:Table)-[r:FK]->(t2:Table)\n",
        "RETURN\n",
        "  t1.name AS `Table 1`,\n",
        "  r.column AS `FK Name`,\n",
        "  t2.name AS `Table 2`\n",
        "\n",
        "Example 2:\n",
        "Question: \"Show orders linked to shipments.\"\n",
        "Cypher:\n",
        "MATCH (t1:Table)-[r:FK]->(t2:Table)\n",
        "WHERE r.column = \"shipment_id\"\n",
        "RETURN\n",
        "  t1.name AS `Table 1`,\n",
        "  r.column AS `FK Name`,\n",
        "  t2.name AS `Table 2`\n",
        "\n",
        "Example 3:\n",
        "Question: \"What are the columns in the users table?\"\n",
        "Cypher:\n",
        "MATCH (t:Table)\n",
        "WHERE t.name = \"users\"\n",
        "RETURN t.columns AS Columns\n",
        "\n",
        "Example 4:\n",
        "Question: \"What is the primary key of the categories table?\"\n",
        "Cypher:\n",
        "MATCH (t:Table)\n",
        "WHERE t.name = \"categories\"\n",
        "RETURN t.columns AS Columns\n",
        "\n",
        "Example 5:\n",
        "Question: \"Which columns in the orders table are foreign keys?\"\n",
        "Cypher:\n",
        "MATCH (t:Table)\n",
        "WHERE t.name = \"orders\"\n",
        "RETURN t.columns AS Columns\n",
        "\n",
        "Example 6:\n",
        "Question: \"List all tables in the database.\"\n",
        "Cypher:\n",
        "MATCH (t:Table)\n",
        "RETURN t.name AS Table\n",
        "\n",
        "Example 7:\n",
        "Question: \"Which tables contain a column named created_at?\"\n",
        "Cypher:\n",
        "MATCH (t:Table)\n",
        "WHERE any(col IN apoc.convert.fromJsonList(t.columns) WHERE col.name = \"created_at\")\n",
        "RETURN t.name AS Table.\n",
        "\n",
        "- If the user refers to \"previous table\", \"previous column\", or any ambiguous reference,\n",
        "  you MUST resolve it using the last conversation memory (memory_buffer).\n",
        "  Replace the ambiguous phrases with the actual table or column name mentioned previously.\n",
        "\n",
        "Conversation Memory:\n",
        "{memory_text}\n",
        "\n",
        "Filtered Schema:\n",
        "{schema_text}\n",
        "\n",
        "User Question:\n",
        "{question}\n",
        "\n",
        "Return:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    payload = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": \"Follow the instructions from the system message exactly when generating the Cypher query.\"}\n",
        "        ],\n",
        "        \"max_tokens\": 600,\n",
        "        \"temperature\": 0.0\n",
        "    }\n",
        "\n",
        "    resp = requests.post(url, headers=headers, json=payload, timeout=120)\n",
        "    resp.raise_for_status()\n",
        "    text = resp.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "\n",
        "    return extract_cypher(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sO1yWU9t4kW7"
      },
      "outputs": [],
      "source": [
        "# This function checks if a generated Cypher query is safe for the schema-only database.\n",
        "# It:\n",
        "# 1) Flattens the query into a single line for easier pattern matching.\n",
        "# 2) Blocks any query containing forbidden write/management commands (e.g., CREATE, DELETE, MERGE).\n",
        "# 3) Ensures the query explicitly targets :Table nodes (schema graph only).\n",
        "# Returns (True, \"\") if safe, otherwise (False, reason).\n",
        "\n",
        "def is_safe_schema_query(q: str) -> Tuple[bool, str]:\n",
        "    q_flat = \" \".join(q.strip().split())\n",
        "    if FORBIDDEN.search(q_flat):\n",
        "        return False, \"Query contains forbidden write/management clauses.\"\n",
        "    if \":Table\" not in q_flat:\n",
        "        return False, \"Query must target :Table nodes (schema graph).\"\n",
        "    return True, \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAcVeyFy6HvD"
      },
      "outputs": [],
      "source": [
        "\n",
        "def llm(prompt: str) -> str:\n",
        "    import os, requests\n",
        "    api_key = os.getenv(\"GROQ_API_KEY\")\n",
        "    if not api_key:\n",
        "        raise RuntimeError(\"GROQ_API_KEY not set in environment\")\n",
        "\n",
        "    url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
        "\n",
        "    payload = {\n",
        "        \"model\": \"llama3-8b-8192\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a professional assistant generating clear answers from database results.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        \"max_tokens\": 600,\n",
        "        \"temperature\": 0.0\n",
        "    }\n",
        "\n",
        "    resp = requests.post(url, headers=headers, json=payload, timeout=120)\n",
        "    resp.raise_for_status()\n",
        "    result = resp.json()\n",
        "    print(\"DEBUG LLM RESPONSE:\", result)\n",
        "    return result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "\n",
        "\n",
        "    resp = requests.post(url, headers=headers, json=payload, timeout=120)\n",
        "    resp.raise_for_status()\n",
        "    return resp.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "\n",
        "\n",
        "def generate_answer_from_cypher_result(question: str, cypher_result: list) -> str:\n",
        "    if not cypher_result:\n",
        "        return \"There is no data matching the question.\"\n",
        "\n",
        "    data_text = \"\\n\".join([\", \".join(f\"{k}: {v}\" for k, v in row.items()) for row in cypher_result])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You have the following user question:\n",
        "\"{question}\"\n",
        "\n",
        "You also have the following data obtained from a Neo4j database after executing a Cypher query:\n",
        "{data_text}\n",
        "\n",
        "Your task:\n",
        "1. Detect the language of the user's question.\n",
        "2. Compose a clear, natural, and easily understandable answer in the same language as the question.\n",
        "3. Focus on conveying the key information directly without showing tables or Cypher queries.\n",
        "4. If the data shows relationships or links between elements, describe them smoothly and clearly.\n",
        "5. Use professional and fluent language with a simple and comprehensible style.\n",
        "\n",
        "Write the final answer so that it is ready to be presented directly to the user.\n",
        "\"\"\"\n",
        "\n",
        "    return llm(prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6xz9zwPBx7B"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 10) LangGraph: State + Nodes\n",
        "# =========================\n",
        "\n",
        "class NewState(TypedDict):\n",
        "    \"\"\"State structure for LangGraph execution.\"\"\"\n",
        "    query: str\n",
        "    reasoning_plan: Dict[str, Any]\n",
        "    cypher_query: str\n",
        "    final_answer:str\n",
        "    cypher_result: List[Dict[str, Any]]\n",
        "    analysis: Dict[str, Any]\n",
        "    cypher_error: str\n",
        "    errors: List[str]\n",
        "    memory_buffer: List[Dict[str, str]]\n",
        "    memory_summary: str\n",
        "\n",
        "\n",
        "# -------- Reasoning Node --------\n",
        "def node_reasoning(state: NewState) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Determines the intent of the user query.\n",
        "\n",
        "    Possible intents:\n",
        "        - 'relations'\n",
        "        - 'columns'\n",
        "        - 'tables_or_misc'\n",
        "\n",
        "    This intent is for guidance only, not directly used in the Cypher.\n",
        "    \"\"\"\n",
        "    q = state.get(\"query\", \"\").lower()\n",
        "\n",
        "    if \"علاقات\" in q or \"relationships\" in q or \"fk\" in q:\n",
        "        intent = \"relations\"\n",
        "    elif \"columns\" in q or \"أعمدة\" in q:\n",
        "        intent = \"columns\"\n",
        "    else:\n",
        "        intent = \"tables_or_misc\"\n",
        "\n",
        "    return {\"reasoning_plan\": {\"intent\": intent}}\n",
        "\n",
        "\n",
        "\n",
        "# -------- Cypher Generation Node --------\n",
        "def node_generate_cypher(state: NewState) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Generates a Cypher query from the user's question using schema snapshot + (optional) memory.\n",
        "    Validates that the generated Cypher is safe.\n",
        "    \"\"\"\n",
        "    snap = get_schema_snapshot(driver)\n",
        "    schema_text = render_schema_text(snap)\n",
        "\n",
        "\n",
        "    memory_text = \"\"\n",
        "    if state.get(\"memory_summary\"):\n",
        "        memory_text += f\"\\n Summary of previous conversations:\\n{state['memory_summary']}\\n\"\n",
        "    if state.get(\"memory_buffer\"):\n",
        "        memory_text += \"\\n Last 3 conversations:\\n\"\n",
        "        for m in state[\"memory_buffer\"]:\n",
        "            memory_text += f\"Q: {m['question']}\\nA: {m['answer']}\\n\"\n",
        "\n",
        "    try:\n",
        "\n",
        "        if memory_text.strip():\n",
        "            cypher = generate_cypher_from_groq(\n",
        "                state[\"query\"],\n",
        "                schema_text,\n",
        "                memory_text\n",
        "             )\n",
        "        else:\n",
        "            cypher = generate_cypher_from_groq(\n",
        "                state[\"query\"],\n",
        "                schema_text,\n",
        "                memory_text\n",
        "            )\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"cypher_query\": \"\",\n",
        "            \"cypher_error\": f\"Groq error: {e}\",\n",
        "            \"errors\": [str(e)]\n",
        "        }\n",
        "\n",
        "    ok, reason = is_safe_schema_query(cypher)\n",
        "    if not ok:\n",
        "        return {\n",
        "            \"cypher_query\": cypher,\n",
        "            \"cypher_error\": f\"Unsafe query: {reason}\",\n",
        "            \"errors\": [reason]\n",
        "        }\n",
        "\n",
        "    return {\"cypher_query\": cypher}\n",
        "\n",
        "\n",
        "# -------- Cypher Execution Node --------\n",
        "def node_run_cypher(state: NewState) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Executes the generated Cypher query on Neo4j and returns the results.\n",
        "    \"\"\"\n",
        "    q = state.get(\"cypher_query\", \"\").strip()\n",
        "    if not q:\n",
        "        return {\"cypher_result\": [], \"cypher_error\": \"No valid Cypher generated.\"}\n",
        "    try:\n",
        "        with driver.session() as sess:\n",
        "            rows = sess.run(q).data()\n",
        "        return {\"cypher_result\": rows}\n",
        "    except Exception as e:\n",
        "        return {\"cypher_result\": [], \"cypher_error\": str(e), \"errors\": [str(e)]}\n",
        "\n",
        "\n",
        "def analyze_and_answer_ar(cypher_result: list) -> str:\n",
        "\n",
        "    if not cypher_result:\n",
        "        return \"There is no data matching the question.\"\n",
        "\n",
        "\n",
        "    lines = []\n",
        "    for row in cypher_result:\n",
        "        parts = []\n",
        "        for k, v in row.items():\n",
        "            parts.append(f\"{k}: {v}\")\n",
        "        lines.append(\", \".join(parts))\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# -------- Analysis Node --------\n",
        "def node_analyze_results(state: NewState) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Processes Cypher results and generates a formatted analysis in Arabic.\n",
        "    \"\"\"\n",
        "    if state.get(\"cypher_error\"):\n",
        "        return {\"analysis\": {\"summary\": f\"Error during execution: {state['cypher_error']}\", \"preview\": []}}\n",
        "\n",
        "    out = analyze_and_answer_ar(state.get(\"cypher_result\", []))\n",
        "    return {\"analysis\": {\"summary\": out, \"preview\": state.get(\"cypher_result\", [])[:5]}}\n",
        "\n",
        "\n",
        "def node_generate_final_answer(state: NewState) -> Dict[str, Any]:\n",
        "    question = state.get(\"query\", \"\")\n",
        "    cypher_result = state.get(\"cypher_result\", [])\n",
        "    try:\n",
        "\n",
        "        answer = generate_answer_from_cypher_result(question, cypher_result)\n",
        "\n",
        "    except Exception as e:\n",
        "        answer = f\"حدث خطأ أثناء توليد الإجابة: {e}\"\n",
        "\n",
        "    return  {\"final_answer\":answer}\n",
        "\n",
        "\n",
        "\n",
        "def node_memory(state: NewState) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Manages short-term memory:\n",
        "    - Keeps last 3 interactions in memory_buffer\n",
        "    - Summarizes older ones into memory_summary\n",
        "    \"\"\"\n",
        "    buffer = state.get(\"memory_buffer\", [])\n",
        "    summary = state.get(\"memory_summary\", \"\")\n",
        "\n",
        "\n",
        "    if state.get(\"query\") and state.get(\"final_answer\"):\n",
        "        buffer.append({\n",
        "            \"question\": state[\"query\"],\n",
        "            \"answer\": state[\"final_answer\"]\n",
        "        })\n",
        "\n",
        "    print(len(buffer))\n",
        "    if len(buffer) > 3:\n",
        "        old = buffer[:-3]\n",
        "        buffer = buffer[-3:]\n",
        "\n",
        "\n",
        "        old_text = \"\\n\".join([f\"Q: {m['question']} → A: {m['answer']}\" for m in old])\n",
        "        summary_prompt = f\"\"\"\n",
        "        You are a conversation summarizer.\n",
        "\n",
        "        Your task:\n",
        "        - Summarize the following conversations briefly and clearly.\n",
        "        - The summary should capture the main topics and answers without unnecessary details.\n",
        "        - Support both Arabic and English (use the same language style of the input).\n",
        "        - Do not rewrite the full Q/A, only the essence.\n",
        "        - Keep it short and coherent (3–4 sentences max).\n",
        "\n",
        "        Conversations to summarize:\n",
        "        {old_text}\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            new_summary = llm(summary_prompt)\n",
        "        except:\n",
        "            new_summary = old_text[:300]\n",
        "\n",
        "        summary = (summary + \"\\n\" + new_summary).strip()\n",
        "\n",
        "    return {\"memory_buffer\": buffer, \"memory_summary\": summary}\n",
        "\n",
        "\n",
        "\n",
        "def node_output(state: NewState) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Final output node — can be extended to format or return final response.\n",
        "    Currently returns an empty dict as placeholder.\n",
        "    \"\"\"\n",
        "    return {}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvWAcbXhBx-t"
      },
      "outputs": [],
      "source": [
        "wf2 = StateGraph(NewState)\n",
        "\n",
        "wf2.add_node(\"memory\", node_memory)\n",
        "wf2.add_node(\"reasoning\", node_reasoning)\n",
        "wf2.add_node(\"generate_cypher\", node_generate_cypher)\n",
        "wf2.add_node(\"run_cypher\", node_run_cypher)\n",
        "wf2.add_node(\"analyze_results\", node_analyze_results)\n",
        "wf2.add_node(\"generate_final_answer\", node_generate_final_answer)\n",
        "wf2.add_node(\"output\", node_output)\n",
        "\n",
        "wf2.add_edge(START, \"reasoning\")\n",
        "wf2.add_edge(\"reasoning\", \"generate_cypher\")\n",
        "wf2.add_edge(\"generate_cypher\", \"run_cypher\")\n",
        "wf2.add_edge(\"run_cypher\", \"analyze_results\")\n",
        "wf2.add_edge(\"analyze_results\", \"generate_final_answer\")\n",
        "wf2.add_edge(\"generate_final_answer\", \"memory\")\n",
        "wf2.add_edge(\"memory\", \"output\")\n",
        "wf2.add_edge(\"output\", END)\n",
        "\n",
        "runner2 = wf2.compile()\n",
        "\n",
        "\n",
        "\n",
        "agent_state = {\n",
        "    \"final_answer\": \"\",\n",
        "    \"query\": \"\",\n",
        "    \"reasoning_plan\": {},\n",
        "    \"cypher_query\": \"\",\n",
        "    \"cypher_result\": [],\n",
        "    \"analysis\": {},\n",
        "    \"cypher_error\": \"\",\n",
        "    \"errors\": [],\n",
        "    \"memory_buffer\": [],\n",
        "    \"memory_summary\": \"\"\n",
        "}\n",
        "\n",
        "def ask_schema_agent(question: str):\n",
        "    global agent_state\n",
        "\n",
        "    agent_state[\"query\"] = question\n",
        "    agent_state[\"final_answer\"] = \"\"\n",
        "\n",
        "\n",
        "    out: NewState = runner2.invoke(agent_state)\n",
        "\n",
        "\n",
        "    agent_state.update(out)\n",
        "\n",
        "    print(\"─\"*70)\n",
        "    print(\"  السؤال:\", question)\n",
        "    print(\"─\"*70)\n",
        "    print(\"\\n الإجابة النهائية:\\n\", out.get(\"final_answer\"))\n",
        "    print(\"─\"*70)\n",
        "    print(\"\\n الملخص:\\n\", (out.get(\"analysis\") or {}).get(\"summary\",\"\"))\n",
        "    print(\"─\"*70)\n",
        "    print(\"\\n الخطة:\", out.get(\"reasoning_plan\"))\n",
        "    print(\"─\"*70)\n",
        "    print(\"\\n الكويري:\\n\", out.get(\"cypher_query\",\"\"))\n",
        "    print(\"─\"*70)\n",
        "    print(\"\\n عينة نتائج:\", out.get(\"cypher_result\", [])[:5])\n",
        "    print(\"─\"*70)\n",
        "    print(\"\\n  آخر 3 محادثات:\", out.get(\"memory_buffer\", []))\n",
        "    print(\"\\n  ملخص المحادثات الأقدم:\", out.get(\"memory_summary\", \"\"))\n",
        "\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SqtRsrTCpAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4fc152c-02ca-48a6-812a-6d490d0091dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG LLM RESPONSE: {'id': 'chatcmpl-ca4a285a-f046-404e-a322-fddea62ddae9', 'object': 'chat.completion', 'created': 1755544512, 'model': 'llama3-8b-8192', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"Based on the user's question, I detect that the language is Arabic.\\n\\nHere's the answer:\\n\\nالاسماء الأعمدة في آخر جدول اتكلمنا عنه هي:\\n\\n* address_id: هو رقم فريد ل каждый عنوان (رقم رئيسي)\\n* user_id: هو رقم فريد يرتبط بالجدول المستخدمين\\n* street: هو عنوان الشارع\\n* city: هو اسم المدينة\\n* state: هو اسم الولاية أو المنطقة\\n* zip_code: هو رمز البريد أو الرمز البريدي\\n* country: هو اسم البلد\\n* created_at: هو توقيت عندما تم إنشاء العنوان\\n* updated_at: هو توقيت عندما تم تحديث العنوان\\n* address_type: هو نوع العنوان (مثل الشحن أو الفاتورة)\\n\\nTranslation:\\n\\nThe column names in the last table we discussed are:\\n\\n* address_id: is a unique identifier for each address (primary key)\\n* user_id: is a foreign key linking to the users table\\n* street: is the street address\\n* city: is the city name\\n* state: is the state or region name\\n* zip_code: is the ZIP or postal code\\n* country: is the country name\\n* created_at: is the timestamp when the address was created\\n* updated_at: is the timestamp when the address was last updated\\n* address_type: is the type of address (e.g., shipping, billing)\"}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'queue_time': 0.00200363, 'prompt_tokens': 418, 'prompt_time': 0.048081647, 'completion_tokens': 298, 'completion_time': 0.270163893, 'total_tokens': 716, 'total_time': 0.31824554}, 'usage_breakdown': None, 'system_fingerprint': 'fp_5b339000ab', 'x_groq': {'id': 'req_01k2z9pstjfvva573z7v2k1xze'}, 'service_tier': 'on_demand'}\n",
            "3\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "  السؤال: هاتلي أسماء الأعمدة في آخر جدول اتكلمنا عنه\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "\n",
            " الإجابة النهائية:\n",
            " Based on the user's question, I detect that the language is Arabic.\n",
            "\n",
            "Here's the answer:\n",
            "\n",
            "الاسماء الأعمدة في آخر جدول اتكلمنا عنه هي:\n",
            "\n",
            "* address_id: هو رقم فريد ل каждый عنوان (رقم رئيسي)\n",
            "* user_id: هو رقم فريد يرتبط بالجدول المستخدمين\n",
            "* street: هو عنوان الشارع\n",
            "* city: هو اسم المدينة\n",
            "* state: هو اسم الولاية أو المنطقة\n",
            "* zip_code: هو رمز البريد أو الرمز البريدي\n",
            "* country: هو اسم البلد\n",
            "* created_at: هو توقيت عندما تم إنشاء العنوان\n",
            "* updated_at: هو توقيت عندما تم تحديث العنوان\n",
            "* address_type: هو نوع العنوان (مثل الشحن أو الفاتورة)\n",
            "\n",
            "Translation:\n",
            "\n",
            "The column names in the last table we discussed are:\n",
            "\n",
            "* address_id: is a unique identifier for each address (primary key)\n",
            "* user_id: is a foreign key linking to the users table\n",
            "* street: is the street address\n",
            "* city: is the city name\n",
            "* state: is the state or region name\n",
            "* zip_code: is the ZIP or postal code\n",
            "* country: is the country name\n",
            "* created_at: is the timestamp when the address was created\n",
            "* updated_at: is the timestamp when the address was last updated\n",
            "* address_type: is the type of address (e.g., shipping, billing)\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "\n",
            " الملخص:\n",
            " Columns: [{\"name\": \"address_id\", \"data_type\": \"Integer\", \"description\": \"Unique identifier for each address (Primary Key)\"}, {\"name\": \"user_id\", \"data_type\": \"Integer\", \"description\": \"Foreign key linking to the users table\"}, {\"name\": \"street\", \"data_type\": \"String\", \"description\": \"Street address\"}, {\"name\": \"city\", \"data_type\": \"String\", \"description\": \"City name\"}, {\"name\": \"state\", \"data_type\": \"String\", \"description\": \"State or region\"}, {\"name\": \"zip_code\", \"data_type\": \"String\", \"description\": \"ZIP or postal code\"}, {\"name\": \"country\", \"data_type\": \"String\", \"description\": \"Country name\"}, {\"name\": \"created_at\", \"data_type\": \"Timestamp\", \"description\": \"Timestamp when the address was created\"}, {\"name\": \"updated_at\", \"data_type\": \"Timestamp\", \"description\": \"Timestamp when the address was last updated\"}, {\"name\": \"address_type\", \"data_type\": \"String\", \"description\": \"Type of address (e.g., shipping, billing)\"}]\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "\n",
            " الخطة: {'intent': 'columns'}\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "\n",
            " الكويري:\n",
            " MATCH (t:Table)\n",
            "WHERE t.name = \"addresses\"\n",
            "RETURN t.columns AS Columns\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "\n",
            " عينة نتائج: [{'Columns': '[{\"name\": \"address_id\", \"data_type\": \"Integer\", \"description\": \"Unique identifier for each address (Primary Key)\"}, {\"name\": \"user_id\", \"data_type\": \"Integer\", \"description\": \"Foreign key linking to the users table\"}, {\"name\": \"street\", \"data_type\": \"String\", \"description\": \"Street address\"}, {\"name\": \"city\", \"data_type\": \"String\", \"description\": \"City name\"}, {\"name\": \"state\", \"data_type\": \"String\", \"description\": \"State or region\"}, {\"name\": \"zip_code\", \"data_type\": \"String\", \"description\": \"ZIP or postal code\"}, {\"name\": \"country\", \"data_type\": \"String\", \"description\": \"Country name\"}, {\"name\": \"created_at\", \"data_type\": \"Timestamp\", \"description\": \"Timestamp when the address was created\"}, {\"name\": \"updated_at\", \"data_type\": \"Timestamp\", \"description\": \"Timestamp when the address was last updated\"}, {\"name\": \"address_type\", \"data_type\": \"String\", \"description\": \"Type of address (e.g., shipping, billing)\"}]'}]\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "\n",
            " 🧠 آخر 3 محادثات: [{'question': 'ما هي الأعمدة في جدول addresses؟', 'answer': 'Based on the user\\'s question \"ما هي الأعمدة في جدول addresses؟\" which is in Arabic, I detect that the language of the question is Arabic.\\n\\nHere\\'s the answer:\\n\\nالأعمدة في جدول addresses هي: address_id، user_id، street، city، state، zip_code، country، created_at، updated_at، address_type. حيث أن address_id هو معرّف فريد لكل عنوان، وuser_id هو مفتاح أجنبي يرتبط بجداول المستخدمين. Additionally, address_type يحدد نوع العنوان (مثل الشحن أو الفاتورة).'}, {'question': 'ما هو الـ primary key في الجدول السابق؟', 'answer': 'Based on the user\\'s question \"ما هو الـ primary key في الجدول السابق؟\", I detect that the language is Arabic.\\n\\nHere\\'s the answer:\\n\\nالـprimary key في الجدول السابق هو \"address_id\". هذا هو المفتاح الرئيسي والوحيد لتعريف كل عنوان برقم فريد.'}, {'question': 'هاتلي أسماء الأعمدة في آخر جدول اتكلمنا عنه', 'answer': \"Based on the user's question, I detect that the language is Arabic.\\n\\nHere's the answer:\\n\\nالاسماء الأعمدة في آخر جدول اتكلمنا عنه هي:\\n\\n* address_id: هو رقم فريد ل каждый عنوان (رقم رئيسي)\\n* user_id: هو رقم فريد يرتبط بالجدول المستخدمين\\n* street: هو عنوان الشارع\\n* city: هو اسم المدينة\\n* state: هو اسم الولاية أو المنطقة\\n* zip_code: هو رمز البريد أو الرمز البريدي\\n* country: هو اسم البلد\\n* created_at: هو توقيت عندما تم إنشاء العنوان\\n* updated_at: هو توقيت عندما تم تحديث العنوان\\n* address_type: هو نوع العنوان (مثل الشحن أو الفاتورة)\\n\\nTranslation:\\n\\nThe column names in the last table we discussed are:\\n\\n* address_id: is a unique identifier for each address (primary key)\\n* user_id: is a foreign key linking to the users table\\n* street: is the street address\\n* city: is the city name\\n* state: is the state or region name\\n* zip_code: is the ZIP or postal code\\n* country: is the country name\\n* created_at: is the timestamp when the address was created\\n* updated_at: is the timestamp when the address was last updated\\n* address_type: is the type of address (e.g., shipping, billing)\"}]\n",
            "\n",
            " 📝 ملخص المحادثات الأقدم: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'هاتلي أسماء الأعمدة في آخر جدول اتكلمنا عنه',\n",
              " 'reasoning_plan': {'intent': 'columns'},\n",
              " 'cypher_query': 'MATCH (t:Table)\\nWHERE t.name = \"addresses\"\\nRETURN t.columns AS Columns',\n",
              " 'final_answer': \"Based on the user's question, I detect that the language is Arabic.\\n\\nHere's the answer:\\n\\nالاسماء الأعمدة في آخر جدول اتكلمنا عنه هي:\\n\\n* address_id: هو رقم فريد ل каждый عنوان (رقم رئيسي)\\n* user_id: هو رقم فريد يرتبط بالجدول المستخدمين\\n* street: هو عنوان الشارع\\n* city: هو اسم المدينة\\n* state: هو اسم الولاية أو المنطقة\\n* zip_code: هو رمز البريد أو الرمز البريدي\\n* country: هو اسم البلد\\n* created_at: هو توقيت عندما تم إنشاء العنوان\\n* updated_at: هو توقيت عندما تم تحديث العنوان\\n* address_type: هو نوع العنوان (مثل الشحن أو الفاتورة)\\n\\nTranslation:\\n\\nThe column names in the last table we discussed are:\\n\\n* address_id: is a unique identifier for each address (primary key)\\n* user_id: is a foreign key linking to the users table\\n* street: is the street address\\n* city: is the city name\\n* state: is the state or region name\\n* zip_code: is the ZIP or postal code\\n* country: is the country name\\n* created_at: is the timestamp when the address was created\\n* updated_at: is the timestamp when the address was last updated\\n* address_type: is the type of address (e.g., shipping, billing)\",\n",
              " 'cypher_result': [{'Columns': '[{\"name\": \"address_id\", \"data_type\": \"Integer\", \"description\": \"Unique identifier for each address (Primary Key)\"}, {\"name\": \"user_id\", \"data_type\": \"Integer\", \"description\": \"Foreign key linking to the users table\"}, {\"name\": \"street\", \"data_type\": \"String\", \"description\": \"Street address\"}, {\"name\": \"city\", \"data_type\": \"String\", \"description\": \"City name\"}, {\"name\": \"state\", \"data_type\": \"String\", \"description\": \"State or region\"}, {\"name\": \"zip_code\", \"data_type\": \"String\", \"description\": \"ZIP or postal code\"}, {\"name\": \"country\", \"data_type\": \"String\", \"description\": \"Country name\"}, {\"name\": \"created_at\", \"data_type\": \"Timestamp\", \"description\": \"Timestamp when the address was created\"}, {\"name\": \"updated_at\", \"data_type\": \"Timestamp\", \"description\": \"Timestamp when the address was last updated\"}, {\"name\": \"address_type\", \"data_type\": \"String\", \"description\": \"Type of address (e.g., shipping, billing)\"}]'}],\n",
              " 'analysis': {'summary': 'Columns: [{\"name\": \"address_id\", \"data_type\": \"Integer\", \"description\": \"Unique identifier for each address (Primary Key)\"}, {\"name\": \"user_id\", \"data_type\": \"Integer\", \"description\": \"Foreign key linking to the users table\"}, {\"name\": \"street\", \"data_type\": \"String\", \"description\": \"Street address\"}, {\"name\": \"city\", \"data_type\": \"String\", \"description\": \"City name\"}, {\"name\": \"state\", \"data_type\": \"String\", \"description\": \"State or region\"}, {\"name\": \"zip_code\", \"data_type\": \"String\", \"description\": \"ZIP or postal code\"}, {\"name\": \"country\", \"data_type\": \"String\", \"description\": \"Country name\"}, {\"name\": \"created_at\", \"data_type\": \"Timestamp\", \"description\": \"Timestamp when the address was created\"}, {\"name\": \"updated_at\", \"data_type\": \"Timestamp\", \"description\": \"Timestamp when the address was last updated\"}, {\"name\": \"address_type\", \"data_type\": \"String\", \"description\": \"Type of address (e.g., shipping, billing)\"}]',\n",
              "  'preview': [{'Columns': '[{\"name\": \"address_id\", \"data_type\": \"Integer\", \"description\": \"Unique identifier for each address (Primary Key)\"}, {\"name\": \"user_id\", \"data_type\": \"Integer\", \"description\": \"Foreign key linking to the users table\"}, {\"name\": \"street\", \"data_type\": \"String\", \"description\": \"Street address\"}, {\"name\": \"city\", \"data_type\": \"String\", \"description\": \"City name\"}, {\"name\": \"state\", \"data_type\": \"String\", \"description\": \"State or region\"}, {\"name\": \"zip_code\", \"data_type\": \"String\", \"description\": \"ZIP or postal code\"}, {\"name\": \"country\", \"data_type\": \"String\", \"description\": \"Country name\"}, {\"name\": \"created_at\", \"data_type\": \"Timestamp\", \"description\": \"Timestamp when the address was created\"}, {\"name\": \"updated_at\", \"data_type\": \"Timestamp\", \"description\": \"Timestamp when the address was last updated\"}, {\"name\": \"address_type\", \"data_type\": \"String\", \"description\": \"Type of address (e.g., shipping, billing)\"}]'}]},\n",
              " 'cypher_error': '',\n",
              " 'errors': [],\n",
              " 'memory_buffer': [{'question': 'ما هي الأعمدة في جدول addresses؟',\n",
              "   'answer': 'Based on the user\\'s question \"ما هي الأعمدة في جدول addresses؟\" which is in Arabic, I detect that the language of the question is Arabic.\\n\\nHere\\'s the answer:\\n\\nالأعمدة في جدول addresses هي: address_id، user_id، street، city، state، zip_code، country، created_at، updated_at، address_type. حيث أن address_id هو معرّف فريد لكل عنوان، وuser_id هو مفتاح أجنبي يرتبط بجداول المستخدمين. Additionally, address_type يحدد نوع العنوان (مثل الشحن أو الفاتورة).'},\n",
              "  {'question': 'ما هو الـ primary key في الجدول السابق؟',\n",
              "   'answer': 'Based on the user\\'s question \"ما هو الـ primary key في الجدول السابق؟\", I detect that the language is Arabic.\\n\\nHere\\'s the answer:\\n\\nالـprimary key في الجدول السابق هو \"address_id\". هذا هو المفتاح الرئيسي والوحيد لتعريف كل عنوان برقم فريد.'},\n",
              "  {'question': 'هاتلي أسماء الأعمدة في آخر جدول اتكلمنا عنه',\n",
              "   'answer': \"Based on the user's question, I detect that the language is Arabic.\\n\\nHere's the answer:\\n\\nالاسماء الأعمدة في آخر جدول اتكلمنا عنه هي:\\n\\n* address_id: هو رقم فريد ل каждый عنوان (رقم رئيسي)\\n* user_id: هو رقم فريد يرتبط بالجدول المستخدمين\\n* street: هو عنوان الشارع\\n* city: هو اسم المدينة\\n* state: هو اسم الولاية أو المنطقة\\n* zip_code: هو رمز البريد أو الرمز البريدي\\n* country: هو اسم البلد\\n* created_at: هو توقيت عندما تم إنشاء العنوان\\n* updated_at: هو توقيت عندما تم تحديث العنوان\\n* address_type: هو نوع العنوان (مثل الشحن أو الفاتورة)\\n\\nTranslation:\\n\\nThe column names in the last table we discussed are:\\n\\n* address_id: is a unique identifier for each address (primary key)\\n* user_id: is a foreign key linking to the users table\\n* street: is the street address\\n* city: is the city name\\n* state: is the state or region name\\n* zip_code: is the ZIP or postal code\\n* country: is the country name\\n* created_at: is the timestamp when the address was created\\n* updated_at: is the timestamp when the address was last updated\\n* address_type: is the type of address (e.g., shipping, billing)\"}],\n",
              " 'memory_summary': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 362
        }
      ],
      "source": [
        "ask_schema_agent(\"هاتلي أسماء الأعمدة في آخر جدول اتكلمنا عنه\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhw-Adk2zr-i"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e40fb782ff5e4effae68cdd53faa9aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25730ebb23cb4cbdadba8af6f9b510bb",
              "IPY_MODEL_c9f9d712bca641f99ea55fcabcf207ac",
              "IPY_MODEL_eb64911f78f84cd39d3071d35196d2cd"
            ],
            "layout": "IPY_MODEL_4b3aec6e05534e998c30271684e9c684"
          }
        },
        "25730ebb23cb4cbdadba8af6f9b510bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fedcddb9543643f786a39cbbe25cd500",
            "placeholder": "​",
            "style": "IPY_MODEL_14ffb06c91e5435386f30e59ce177930",
            "value": "Batches: 100%"
          }
        },
        "c9f9d712bca641f99ea55fcabcf207ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fcddb30eb034e269eea18855dd4401c",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6859b8823dc49fb9b0da8baf222c40c",
            "value": 4
          }
        },
        "eb64911f78f84cd39d3071d35196d2cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84bab26ac0784bf59a49c8721914ace0",
            "placeholder": "​",
            "style": "IPY_MODEL_474b4c6bdf5b4502acb505ba1e18e5f3",
            "value": " 4/4 [00:02&lt;00:00,  1.98it/s]"
          }
        },
        "4b3aec6e05534e998c30271684e9c684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fedcddb9543643f786a39cbbe25cd500": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14ffb06c91e5435386f30e59ce177930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fcddb30eb034e269eea18855dd4401c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6859b8823dc49fb9b0da8baf222c40c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84bab26ac0784bf59a49c8721914ace0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "474b4c6bdf5b4502acb505ba1e18e5f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}